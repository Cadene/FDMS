{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TME1 - Recommendation Sociale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données\n",
    "\n",
    "La fonctions pour charger la base Movie Lens 100k.\n",
    "On récupère:\n",
    "- Les scores: Une liste de triplet [user, movie, rating]\n",
    "- Les liens: Une liste de triplet [source, target, weight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loadMovieLens(path='./data', dataFile='/u.data', dataFileTest=None):\n",
    "    ratings = []\n",
    "    ratings_test = []\n",
    "    links = []\n",
    "    users = set()\n",
    "    movies = set()\n",
    "    for line in open(path+dataFile):\n",
    "        (userId,movieId,rating,ts)=line.split('\\t')\n",
    "        ratings.append([userId, movieId, float(rating)/5])\n",
    "        users.add(userId)\n",
    "        movies.add(movieId)\n",
    "    for line in open(path+'/u.links'):\n",
    "        l = line[:-1].split('\\t')\n",
    "        source = l[0]\n",
    "        if source in users:\n",
    "            for target in l[1:]:\n",
    "                if target in users:\n",
    "                    links.append([source, target, 1])\n",
    "    if (dataFileTest):\n",
    "        for line in open(path+dataFileTest):\n",
    "            (userId,movieId,rating,ts)=line.split('\\t')\n",
    "            if (userId in users) and (movieId in movies):\n",
    "                ratings_test.append([userId, movieId, float(rating)/5])\n",
    "    return links, ratings, ratings_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorisation matricielle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class matrixFactorisation():\n",
    "    def __init__(self, k, lambdaC=0.2, lambdaU=0.2, lambdaV=0.2, lambdaZ=0.2, eps=1e-5, maxIter=2000):\n",
    "        self.k = k\n",
    "        self.lambdaC = lambdaC\n",
    "        self.lambdaU = lambdaU\n",
    "        self.lambdaV = lambdaV\n",
    "        self.lambdaZ = lambdaZ\n",
    "        self.eps = eps\n",
    "        self.maxIter = maxIter\n",
    "    def fit(self, tripletsUsersItems, tripletsLinks):\n",
    "        self.u = {}\n",
    "        self.v = {}\n",
    "        self.z = {}\n",
    "        self.loss = []\n",
    "        #Choix du paramètre a optimisé en cas d'optimisation alternée\n",
    "        for i in xrange(self.maxIter):\n",
    "            lossUV = 0\n",
    "            lossUZ = 0\n",
    "            lossReg = 0\n",
    "            for j in xrange(len(tripletsUsersItems)):\n",
    "                # Ratings --------------------------------------------------------------------------------------------\n",
    "                r = np.random.randint(len(tripletsUsersItems)) \n",
    "                user =   tripletsUsersItems[r][0]\n",
    "                item =   tripletsUsersItems[r][1]\n",
    "                rating = tripletsUsersItems[r][2]\n",
    "                if not user in self.u:\n",
    "                    self.u[user] = np.random.rand(1,self.k)\n",
    "                if not item in self.v:\n",
    "                    self.v[item] = np.random.rand(self.k,1)\n",
    "                expUV = np.exp(self.u[user].dot(self.v[item])[0][0])\n",
    "                logistiqueUV = (1.0/(1 + expUV))\n",
    "                tmp = logistiqueUV - rating\n",
    "                self.u[user] = self.u[user] - self.eps * tmp * expUV * (logistiqueUV **2) * self.v[item].transpose()\n",
    "                self.v[item] = self.v[item] - self.eps * tmp * expUV * (logistiqueUV **2) * self.u[user].transpose()\n",
    "                lossUV = lossUV + tmp*tmp/2. \n",
    "                # Links ---------------------------------------------------------------------------------------------\n",
    "                r = np.random.randint(len(tripletsLinks))\n",
    "                userSource = tripletsLinks[r][0]\n",
    "                userTarget = tripletsLinks[r][1]\n",
    "                linkScore  = tripletsLinks[r][2]\n",
    "                if not userSource in self.u:\n",
    "                    self.u[userSource] = np.random.rand(1,self.k)\n",
    "                if not userTarget in self.z:\n",
    "                    self.z[userTarget] = np.random.rand(self.k,1)\n",
    "                expUZ = np.exp(self.u[userSource].dot(self.z[userTarget])[0][0])\n",
    "                logistiqueUZ = (1.0/(1 + expUZ))\n",
    "                tmp = logistiqueUZ - linkScore\n",
    "                self.u[userSource] = self.u[userSource] - self.eps * tmp * expUZ * (logistiqueUZ **2) * self.z[userTarget].transpose()\n",
    "                self.z[userTarget] = self.z[userTarget] - self.eps * tmp * expUZ * (logistiqueUZ **2) * self.u[userSource].transpose()\n",
    "                lossUZ = lossUZ + tmp*tmp/2. \n",
    "                # Regularize  --------------------------------------------------------------------------------------\n",
    "                ru = np.random.choice(self.u.keys());\n",
    "                rv = np.random.choice(self.v.keys());\n",
    "                rz = np.random.choice(self.z.keys());\n",
    "                self.u[ru] = self.u[ru] * (1 - self.lambdaU * self.eps)\n",
    "                self.v[rv] = self.v[rv] * (1 - self.lambdaV * self.eps)\n",
    "                self.z[rz] = self.z[rz] * (1 - self.lambdaZ * self.eps)\n",
    "                lossReg = lossReg + np.sqrt((self.u[ru]**2).sum()) + np.sqrt((self.v[rv]**2).sum()) + np.sqrt((self.z[rz]**2).sum())\n",
    "            self.loss.append([lossUV, lossUZ, lossReg])\n",
    "            if (i % 1 == 0):\n",
    "                print i, (lossUV + lossUZ + lossReg) / len(tripletsUsersItems)\n",
    "    def predict(self, tripletsUsersItems):\n",
    "        pred = np.zeros(len(tripletsUsersItems))\n",
    "        for ind,c in enumerate(tripletsUsersItems):\n",
    "            pred[ind] = self.u[c[0]].dot(self.v[c[1]])[0][0]\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests les données Movie Lens 100k\n",
    "\n",
    "Les données Movie Lens 100k comprennent 100 000 scores données par 1000 utilisateurs sur 1700 films.\n",
    "\n",
    "## Préparation des données\n",
    "\n",
    "On extrait aléatoirement une portion (20%) des données pour constituer la base de test, et le reste sera utilisé en apprentissage.\n",
    "\n",
    "Comme on ne souhaite ne pas évaluer les objets et les utilisateurs qui n'ont jamais été rencontré en apprentissage, on retire les couples correspondants de l'ensemble de test.\n",
    "\n",
    "Reste ensuite à reconstruire les deux dictionnaires a partir de ces liste de couples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Chargement\n",
    "links, ratings_train, ratings_test = loadMovieLens(dataFile=\"/u1.train\", dataFileTest=\"/u1.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.13368725017\n",
      "1 3.95543584301\n",
      "2 3.80071924069\n",
      "3 3.65883941656\n",
      "4 3.53270103102\n",
      "5 3.42076618068\n",
      "6 3.30667844923\n",
      "7 3.22176187356\n",
      "8 3.1391312072\n",
      "9 3.06442500201\n",
      "10 2.99704559005\n",
      "11 2.94184376321\n",
      "12 2.88950101126\n",
      "13 2.8412886297\n",
      "14 2.79295786529\n",
      "15 2.7596006539\n",
      "16 2.72443339659\n",
      "17 2.69199660864\n",
      "18 2.66311779102\n",
      "19 2.6402213719\n",
      "20 2.61699512739\n",
      "21 2.59184691913\n",
      "22 2.57058396232\n",
      "23 2.55288723649\n",
      "24 2.53631473833\n",
      "25 2.52100451029\n",
      "26 2.50895046003\n",
      "27 2.50073438692\n",
      "28 2.48680951522\n",
      "29 2.47118760602\n",
      "30 2.4600269524\n",
      "31 2.45950511349\n",
      "32 2.45165461334\n",
      "33 2.44605642771\n",
      "34 2.43963941205\n",
      "35 2.43245932583\n",
      "36 2.42224783115\n",
      "37 2.42499054187\n",
      "38 2.42305965261\n",
      "39 2.41358347574\n",
      "40 2.40989835035\n",
      "41 2.40572543299\n",
      "42 2.40156826487\n",
      "43 2.39336146403\n",
      "44 2.39260156864\n",
      "45 2.39841615518\n",
      "46 2.38834056621\n",
      "47 2.38736924199\n",
      "48 2.38839322096\n",
      "49 2.38818461937\n"
     ]
    }
   ],
   "source": [
    "model = matrixFactorisation(5, eps=1e-2, maxIter=50)\n",
    "model.fit(ratings_train, links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur de test: 0.602970871829\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(ratings_test)\n",
    "print \"Erreur de test:\", ((pred - np.array(np.array(ratings_test)[:,2], float)) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
