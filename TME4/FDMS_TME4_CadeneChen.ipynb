{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TME4 - Filtrage Collaboratif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Université Pierre et Marie Curie (UPMC)\n",
    "- Master Données, Apprentissage, Connaissances (DAC)\n",
    "- Professeur Ludovic Denoyer\n",
    "- Étudiant Rémi Cadène 3000693\n",
    "\n",
    "Dans ce TME, nous nous attaquons à un problème transductif de recommendation. Le but est de retrouver des notes de films données par des utilisateurs. Ainsi, nous devons remplir les cases vides d'une matrice sparse utilisateurs - films contenant des notes comprises entre 0 et 5. Pour ce faire, nous créons deux modèles simples pour la baseline et trois modèles de matrice factorisation appris avec descente de gradient stochastique. Ces trois derniers modèles sont les suivants : sans biais, avec biais utilisateurs et items, et avec biais utilisateurs, items et temporels. Nos modèles sont évalués sur un critère des moindres carrés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loadMovieLens(path='./data100k'):\n",
    "    # Get movie titles\n",
    "    movies={}\n",
    "    for line in open(path+'/u.item'):\n",
    "        (id,title)=line.split('|')[0:2]\n",
    "        movies[id]=title\n",
    "    # Load data\n",
    "    prefs={}\n",
    "    times={}\n",
    "    for line in open(path+'/u.data'):\n",
    "        (user,movieid,rating,ts)=line.split('\\t')\n",
    "        prefs.setdefault(user,{})\n",
    "        prefs[user][movies[movieid]]=float(rating)\n",
    "        times.setdefault(user,{})\n",
    "        times[user][movies[movieid]]=float(ts)\n",
    "    return prefs, times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data, timestamps = loadMovieLens()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation en données de Train et de Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre base de données est constituée de couples (utilisateur, item) associés à un score.\n",
    "Afin d'évaluer nos modèles, nous constituons un ensemble de test composé de 20% de ces couples sélectionnés aléatoirement, et un ensemble d'entrainement composée des 80%. \n",
    "\n",
    "Comme notre problème est transductif, on ne souhaite pas évaluer les items et les utilisateurs n'ayant jamais été rencontré en apprentissage. Ainsi, on retire les couples correspondants de l'ensemble de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Recupère une représentation des données sous la forme triplets [user, item, note]\n",
    "def getCouplesUsersItems(data):\n",
    "    couples = []\n",
    "    for u in data.keys():\n",
    "        for i in data[u].keys():\n",
    "            couples.append([u,i,data[u][i]])\n",
    "    return couples\n",
    "\n",
    "# Split l'ensemble des triplets [user, item, note] en testProp% données de test et (1 - testProp) données de train\n",
    "def splitTrainTest(couples,testProp):\n",
    "    perm = np.random.permutation(couples)\n",
    "    splitIndex = int(testProp * len(couples))\n",
    "    return perm[splitIndex:], perm[:splitIndex]\n",
    "\n",
    "# Construit le dictionnaire des utilisateurs a partir des triplets [user, item, note]\n",
    "def buildUsersDict(couples):\n",
    "    dicUsers = {}\n",
    "    for c in couples:\n",
    "        if not c[0] in dicUsers.keys():\n",
    "            dicUsers[c[0]] = {}\n",
    "        dicUsers[c[0]][c[1]] = float(c[2])\n",
    "    return dicUsers\n",
    "\n",
    "# Construit le dictionnaire des objets a partir des triplets [user, item, note]\n",
    "def buildItemsDict(couples):\n",
    "    dicItems = {}\n",
    "    for c in couples:\n",
    "        if not c[1] in dicItems:\n",
    "            dicItems[c[1]] = {}\n",
    "        dicItems[c[1]][c[0]] = float(c[2])\n",
    "    return dicItems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "couples = getCouplesUsersItems(data)\n",
    "\n",
    "trainCouples, testCouples = splitTrainTest(couples,.20)\n",
    "\n",
    "trainUsers = buildUsersDict(trainCouples)\n",
    "trainItems = buildItemsDict(trainCouples)\n",
    "\n",
    "toDel = []\n",
    "\n",
    "for i,c in enumerate(testCouples):\n",
    "    if not c[0] in trainUsers:\n",
    "        toDel.append(i)\n",
    "    elif not c[1] in trainItems:\n",
    "        toDel.append(i)\n",
    "\n",
    "testCouples = np.delete(testCouples, toDel, 0)\n",
    "\n",
    "testUsers  = buildUsersDict(testCouples)\n",
    "testItems  = buildItemsDict(testCouples)\n",
    "\n",
    "#print len(trainUsers), len(testUsers)\n",
    "#print len(trainItems), len(testItems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 1 : Moyenne par utilisateur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce modèle simple calcule la note moyenne donnée pour chaque utilisateur à partir de l'ensemble d'apprentissage.\n",
    "Pour un utilisateur, c'est cette même note moyenne qui est associée à chaque item de l'ensemble de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class baselineMeanUsers():\n",
    "    def __init__(self):            \n",
    "        self.mean = {}\n",
    "    def fit(self, dataUsers):\n",
    "        self.mean = {}\n",
    "        for u in dataUsers.keys():\n",
    "            self.mean[u] = 0\n",
    "            for i in dataUsers[u].keys():\n",
    "                self.mean[u] = self.mean[u] + dataUsers[u][i]\n",
    "            self.mean[u] = self.mean[u] / len(dataUsers[u])\n",
    "    def predict(self, couplesTest):\n",
    "        pred = np.zeros(len(couplesTest))\n",
    "        for ind,c in enumerate(couplesTest):\n",
    "            pred[ind] = self.mean[c[0]]\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erreur en test: 1.08572773402\n"
     ]
    }
   ],
   "source": [
    "model1 = baselineMeanUsers()\n",
    "model1.fit(trainUsers)\n",
    "pred = model1.predict(testCouples)\n",
    "print \"erreur en test:\", ((pred - np.array(testCouples[:,2], float)) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 2 : Moyenne par item\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De même, ce modèle simple calcule la note moyenne pour chaque item. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class baselineMeanItems():\n",
    "    def __init__(self):            \n",
    "        self.mean = {}\n",
    "    def fit(self, dataItems):\n",
    "        self.mean = {}\n",
    "        for i in dataItems.keys():\n",
    "            self.mean[i] = 0\n",
    "            for u in dataItems[i].keys():\n",
    "                self.mean[i] = self.mean[i] + dataItems[i][u]\n",
    "            self.mean[i] = self.mean[i] / len(dataItems[i])\n",
    "    def predict(self, couplesTest):\n",
    "        pred = np.zeros(len(couplesTest))\n",
    "        for ind,c in enumerate(couplesTest):\n",
    "            pred[ind] = self.mean[c[1]]\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erreur en test: 1.03931944836\n"
     ]
    }
   ],
   "source": [
    "model2 = baselineMeanItems()\n",
    "model2.fit(trainItems)\n",
    "pred = model2.predict(testCouples)\n",
    "print \"erreur en test:\", ((pred - np.array(testCouples[:,2], float)) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorisation de Matrices\n",
    "\n",
    "Ce modèle permet de plonger les utilisateurs et les items dans un espace (latent) de plus faible dimension et ainsi de pouvoir calculer le score final à l'aide d'une similarité entre utilisateurs et items : $r_{u,i} = <p_u ; q_i>$\n",
    "\n",
    "On rajoute des contraintes sur P et Q en ajoutant au coût MSE leur norme $\\ell_2$ afin de contrôler le sur-apprentissage.\n",
    "\n",
    "Hyperparamètres :\n",
    "- le nombre de dimensions de l'espace latent $k$\n",
    "- le coefficient de régularisation $lambd$ ($\\lambda$)\n",
    "- le pas du gradient $eps$\n",
    "- le nombre d'itération $maxIter$\n",
    "\n",
    "Paramètres : \n",
    "- la matrice des représentations latentes des utilisateurs $P_{nb\\_users, k}$\n",
    "- la matrice des représentations latentes des items $Q_{nb\\_items, k}$ \n",
    "\n",
    "Minimisation de l'erreur :\n",
    "- $C(P,Q) = ||X - PQ||^2 + \\lambda * (||P||_2 + ||Q||_2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class matrixFactorisation():\n",
    "    def __init__(self, k, lambd=0.2, eps=1e-5, maxIter=2000, alternate=0):\n",
    "        self.k = k\n",
    "        self.lambd = lambd\n",
    "        self.eps = eps\n",
    "        self.maxIter = maxIter\n",
    "        self.alternate = alternate #alterne entre la mise à jour de P ou Q\n",
    "    def fit(self, dataUsers, dataItems, couples):\n",
    "        self.p = {}\n",
    "        self.q = {}\n",
    "        self.couples = couples\n",
    "        self.loss = []\n",
    "        optimP = True\n",
    "        optimQ = (self.alternate == 0)\n",
    "        for i in xrange(self.maxIter):\n",
    "            loss = 0\n",
    "            for j in xrange(len(couples)):\n",
    "                r = np.random.randint(len(couples))\n",
    "                user = couples[r][0]\n",
    "                item = couples[r][1]\n",
    "                if not user in self.p:\n",
    "                    self.p[user] = np.random.rand(1,self.k)\n",
    "                if not item in self.q:\n",
    "                    self.q[item] = np.random.rand(self.k,1)\n",
    "                tmp = dataUsers[user][item] - self.p[user].dot(self.q[item])[0][0]\n",
    "                if (optimP):\n",
    "                    self.p[user] = (1 - self.lambd * self.eps) * self.p[user] + self.eps * 2 * tmp * self.q[item].transpose()\n",
    "                if (optimQ):\n",
    "                    self.q[item] = (1 - self.lambd * self.eps) * self.q[item] + self.eps * 2 * tmp * self.p[user].transpose()\n",
    "                loss = loss + tmp*tmp #Sans régularisation\n",
    "            self.loss.append(loss)\n",
    "            if (self.alternate != 0):\n",
    "                if (i % self.alternate == 0):\n",
    "                    optimP = optimQ\n",
    "                    optimQ = 1 - optimQ\n",
    "                    print i, loss / len(couples)\n",
    "            else:\n",
    "                if (i % 100 == 0):\n",
    "                    print i, loss / len(couples)\n",
    "    def predict(self, couplesTest):\n",
    "        pred = np.zeros(len(couplesTest))\n",
    "        for ind,c in enumerate(couplesTest):\n",
    "            pred[ind] = self.p[c[0]].dot(self.q[c[1]])[0][0]\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.829537706\n",
      "100 1.30712001798\n",
      "200 1.07948970774\n",
      "300 0.997287439085\n",
      "400 0.952657605705\n",
      "500 0.917643772482\n",
      "600 0.89365902144\n",
      "700 0.888028692502\n",
      "800 0.869048170694\n",
      "900 0.868529460105\n",
      "1000 0.858853615837\n",
      "1100 0.863836741598\n",
      "1200 0.852722256483\n",
      "1300 0.842192524637\n",
      "1400 0.841983968252\n",
      "1500 0.844243257703\n",
      "1600 0.837896616117\n",
      "1700 0.837744282998\n",
      "1800 0.832008944357\n",
      "1900 0.83920613112\n"
     ]
    }
   ],
   "source": [
    "model3 = matrixFactorisation(10, alternate=0)\n",
    "model3.fit(trainUsers, trainItems, trainCouples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(model3.loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur de test: 0.909580818424\n"
     ]
    }
   ],
   "source": [
    "pred = model3.predict(testCouples)\n",
    "print \"Erreur de test:\", ((pred - np.array(testCouples[:,2], float)) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'erreur de test obtenue est nettement inférieure à celles des modèles simples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorisation de Matrices avec biais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe généralement un certain biais sur les items. Par exemple, les blockbusters reçoivent beaucoup plus de notes que les films indépendants.\n",
    "\n",
    "On observe aussi un certain biais sur les utilisateurs. Par exemple, il peut exister deux catégories d'utilisateurs : les optimistes qui donnent généralement des bonnes notes, et les pessimistes qui donnent généralement des mauvaises notes.\n",
    "\n",
    "Pour prendre en compte ces biais, on cosidère que chaque item a une note moyenne qui ne dépend pas de l'utilisateur et chaque utilisateur est associé à une note moyenne qui ne dépend pas de l'item.\n",
    "\n",
    "De fait, il s'agit de trouver P,Q qui minimise l'erreur suivante :\n",
    "- $min_{P,Q,Bu,Bi,\\mu} \\sum_{(u,i)} (X(u,i) - (\\mu + Bu(u) + Bi(i) + <P(u), Q(i)>))^2 + \\lambda * (||P||_2 + ||Q||_2 + ||Bu||_2 + ||Bi||_2)$\n",
    "\n",
    "A chaque itération, il faudra alors mettre à jour la matrice latente d'utilisateurs P, la matrice latente d'items Q, le biais utilisateurs $Bu$, le biais items $Bi$ et le biais d'atténuation $\\mu$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class matrixFactorisationBiais():\n",
    "    def __init__(self, k, lambd=0.2, eps=1e-5, maxIter=10000, alternate=0):\n",
    "        self.k = k\n",
    "        self.lambd = lambd\n",
    "        self.eps = eps\n",
    "        self.maxIter = maxIter\n",
    "        self.alternate = alternate\n",
    "    def fit(self, dataUsers, dataItems, couples):\n",
    "        self.p = {}\n",
    "        self.q = {}\n",
    "        self.bu = {}\n",
    "        self.bi = {}\n",
    "        self.mu = np.random.random() * 2 - 1\n",
    "        self.loss = []\n",
    "        optimP = True\n",
    "        optimQ = (self.alternate == 0)\n",
    "        for i in xrange(self.maxIter):\n",
    "            loss = 0\n",
    "            for j in xrange(len(couples)):\n",
    "                r = np.random.randint(len(couples))\n",
    "                user = couples[r][0]\n",
    "                item = couples[r][1]\n",
    "                if not user in self.p:\n",
    "                    self.p[user] = np.random.rand(1,self.k) * 2 - 1\n",
    "                    self.bu[user] = np.random.rand() * 2 - 1\n",
    "                if not item in self.q:\n",
    "                    self.q[item] = np.random.rand(self.k,1) * 2 - 1\n",
    "                    self.bi[item] = np.random.rand() * 2 - 1\n",
    "                tmp = dataUsers[user][item] - (self.mu + self.bi[item] + self.bu[user] + self.p[user].dot(self.q[item])[0][0])\n",
    "                if (optimP):\n",
    "                    self.p[user] = (1 - self.lambd * self.eps) * self.p[user] + self.eps * 2 * tmp * self.q[item].transpose()\n",
    "                    self.bu[user] = (1 - self.lambd * self.eps) * self.bu[user] + self.eps * 2 * tmp\n",
    "                if (optimQ):\n",
    "                    self.q[item] = (1 - self.lambd * self.eps) * self.q[item] + self.eps * 2 * tmp * self.p[user].transpose()\n",
    "                    self.bi[item] = (1 - self.lambd * self.eps) * self.bi[item] + self.eps * 2 * tmp\n",
    "                self.mu = (1 - self.lambd * self.eps) * self.mu + self.eps * 2 * tmp\n",
    "                loss = loss + tmp*tmp #Sans régularisation\n",
    "            self.loss.append(loss)\n",
    "            if (self.alternate != 0):\n",
    "                if (i % self.alternate == 0):\n",
    "                    optimP = optimQ\n",
    "                    optimQ = 1 - optimQ\n",
    "                    print i, loss / len(couples)\n",
    "            else:\n",
    "                if (i % 100 == 0):\n",
    "                    print i, loss / len(couples)\n",
    "    def predict(self, couplesTest):\n",
    "        pred = np.zeros(len(couplesTest))\n",
    "        for ind,c in enumerate(couplesTest):\n",
    "            pred[ind] = self.mu + self.bu[c[0]] + self.bi[c[1]] + self.p[c[0]].dot(self.q[c[1]])[0][0]\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7.84879153329\n",
      "100 2.20841845373\n",
      "200 1.78135161261\n",
      "300 1.50665884754\n",
      "400 1.36179780473\n",
      "500 1.27271620043\n",
      "600 1.18725411492\n",
      "700 1.13627534893\n",
      "800 1.08727524392\n",
      "900 1.05073590425\n",
      "1000 1.01654162391\n",
      "1100 1.00560542752\n",
      "1200 0.97646470343\n",
      "1300 0.967124816417\n",
      "1400 0.950623023452\n",
      "1500 0.94110060945\n",
      "1600 0.928282231649\n",
      "1700 0.913576022519\n",
      "1800 0.90368654631\n",
      "1900 0.889919122869\n",
      "2000 0.886632345112\n",
      "2100 0.87637080938\n",
      "2200 0.879517708617\n",
      "2300 0.872767670014\n",
      "2400 0.863631577612\n",
      "2500 0.853651927641\n",
      "2600 0.849095197608\n",
      "2700 0.855620811393\n",
      "2800 0.843541206755\n",
      "2900 0.844477373661\n",
      "3000 0.841569307323\n",
      "3100 0.842851965166\n",
      "3200 0.833419184501\n",
      "3300 0.824305787357\n",
      "3400 0.832219602661\n",
      "3500 0.825525993355\n",
      "3600 0.824484381541\n",
      "3700 0.816336008193\n",
      "3800 0.815159277787\n",
      "3900 0.814879026143\n",
      "4000 0.813612289994\n",
      "4100 0.813574241683\n",
      "4200 0.802972958589\n",
      "4300 0.811059457145\n",
      "4400 0.804668565967\n",
      "4500 0.800480942454\n",
      "4600 0.803039122674\n",
      "4700 0.798049443498\n",
      "4800 0.797483731818\n",
      "4900 0.796329706711\n",
      "5000 0.789174918466\n",
      "5100 0.791177143524\n",
      "5200 0.786608210483\n",
      "5300 0.788704131071\n",
      "5400 0.784770640646\n",
      "5500 0.781415889645\n",
      "5600 0.788106017931\n",
      "5700 0.780995331137\n",
      "5800 0.768241354766\n",
      "5900 0.772388355041\n",
      "6000 0.770515710955\n",
      "6100 0.778211415174\n",
      "6200 0.774700133019\n",
      "6300 0.779695322178\n",
      "6400 0.766843838768\n",
      "6500 0.766804444781\n",
      "6600 0.761505748972\n",
      "6700 0.765190115456\n",
      "6800 0.765347829132\n",
      "6900 0.764181275541\n",
      "7000 0.755660379782\n",
      "7100 0.756277149286\n",
      "7200 0.758423586497\n",
      "7300 0.758824592247\n",
      "7400 0.755913434182\n",
      "7500 0.74682818907\n",
      "7600 0.748383203179\n",
      "7700 0.746113895937\n",
      "7800 0.739821600998\n",
      "7900 0.748992464971\n",
      "8000 0.744560945647\n",
      "8100 0.747488962401\n",
      "8200 0.74483471385\n",
      "8300 0.741946324107\n",
      "8400 0.737835278301\n",
      "8500 0.733317991715\n",
      "8600 0.737173402373\n",
      "8700 0.742342540094\n",
      "8800 0.731533756674\n",
      "8900 0.728225962676\n",
      "9000 0.728983224634\n",
      "9100 0.730584312803\n",
      "9200 0.726048811083\n",
      "9300 0.724669003038\n",
      "9400 0.722043913633\n",
      "9500 0.729239252944\n",
      "9600 0.721099577929\n",
      "9700 0.718941520324\n",
      "9800 0.723550634396\n",
      "9900 0.713612781405\n"
     ]
    }
   ],
   "source": [
    "model4 = matrixFactorisationBiais(10, alternate=0)\n",
    "model4.fit(trainUsers, trainItems, trainCouples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(model4.loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90047122114\n"
     ]
    }
   ],
   "source": [
    "pred = model4.predict(testCouples)\n",
    "print ((pred - np.array(testCouples[:,2], float)) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate que le score en test est très proche du modèle sans biais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biais Temporel\n",
    "\n",
    "## Visualisition des notes en fonction du temps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate généralement un biais temporel, en effet les notes peuvent changer en fonction de l'époque et du temps. Par exemple, durant les périodes de fêtes, on peut observer une augmentation du nombre de notes données.\n",
    "\n",
    "Pour intégrer ce biais temporel, on modifie notre fonction d'erreur de la façon suivante :\n",
    "- $min_{P,Q,Bu,Bi,\\mu} \\sum_{(u,i,t)} (X(u,i) - (\\mu + Bu(u,t) + Bi(i,t) + <P(u), Q(i)>))^2 + \\lambda * (||P||_2 + ||Q||_2 + ||Bu(t)||_2 + ||Bi(t)||_2)$\n",
    "\n",
    "avec $Bu$ et $Bi$ des matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTimeBins(couples, timedic, nbins):\n",
    "    timestamps = np.zeros(len(couples))\n",
    "    for i,c in enumerate(couples):\n",
    "        timestamps[i] = timedic[c[0]][c[1]]\n",
    "    time_bins = np.linspace(np.min(timestamps), np.max(timestamps), nbins+1)\n",
    "    times = np.zeros(len(couples))\n",
    "    for i in xrange(1,len(time_bins)):\n",
    "        times = times + (timestamps > time_bins[i])\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nbins = 5\n",
    "\n",
    "times = getTimeBins(couples, timestamps, nbins)\n",
    "ratings = np.array(np.array(couples)[:,2], float)\n",
    "plt.figure()\n",
    "for i in xrange(nbins):\n",
    "    histi = np.bincount(np.array(ratings[times==i], int))\n",
    "    plt.plot(1.* histi / histi.sum() , 'o-')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class matrixFactorisationBiaisTemporel():\n",
    "    def __init__(self, k=10, ntimes=5, lambd=0.2, eps=1e-5, maxIter=10000, alternate=0):\n",
    "        self.k = k\n",
    "        self.ntimes = ntimes\n",
    "        self.lambd = lambd\n",
    "        self.eps = eps\n",
    "        self.maxIter = maxIter\n",
    "        self.alternate = alternate\n",
    "    def fit(self, dataUsers, dataItems, couples, times):\n",
    "        self.p = {}\n",
    "        self.q = {}\n",
    "        self.bu = {}\n",
    "        self.bi = {}\n",
    "        self.mu = np.random.rand(self.ntimes) * 2 - 1\n",
    "        self.loss = []\n",
    "        optimP = True\n",
    "        optimQ = (self.alternate == 0)\n",
    "        for i in xrange(self.maxIter):\n",
    "            loss = 0\n",
    "            for j in xrange(len(couples)):\n",
    "                r = np.random.randint(len(couples))\n",
    "                user = couples[r][0]\n",
    "                item = couples[r][1]\n",
    "                time = times[r]\n",
    "                if not user in self.p:\n",
    "                    self.p[user] = np.random.rand(1,self.k) * 2 - 1\n",
    "                    self.bu[user] = np.random.rand(self.ntimes) * 2 - 1\n",
    "                if not item in self.q:\n",
    "                    self.q[item] = np.random.rand(self.k,1) * 2 - 1\n",
    "                    self.bi[item] = np.random.rand(self.ntimes) * 2 - 1\n",
    "                tmp = dataUsers[user][item] - (self.mu[time] + self.bi[item][time] + self.bu[user][time] + self.p[user].dot(self.q[item])[0][0])\n",
    "                if (optimP):\n",
    "                    self.p[user] = (1 - self.lambd * self.eps) * self.p[user] + self.eps * 2 * tmp * self.q[item].transpose()\n",
    "                    self.bu[user] = (1 - self.lambd * self.eps) * self.bu[user] + self.eps * 2 * tmp\n",
    "                if (optimQ):\n",
    "                    self.q[item] = (1 - self.lambd * self.eps) * self.q[item] + self.eps * 2 * tmp * self.p[user].transpose()\n",
    "                    self.bi[item] = (1 - self.lambd * self.eps) * self.bi[item] + self.eps * 2 * tmp\n",
    "                self.mu = (1 - self.lambd * self.eps) * self.mu + self.eps * 2 * tmp\n",
    "                loss = loss + tmp*tmp #Sans régularisation\n",
    "            self.loss.append(loss)\n",
    "            if (self.alternate != 0):\n",
    "                if (i % self.alternate == 0):\n",
    "                    optimP = optimQ\n",
    "                    optimQ = 1 - optimQ\n",
    "                    print i, loss / len(couples)\n",
    "            else:\n",
    "                if (i % 100 == 0):\n",
    "                    print i, loss / len(couples)\n",
    "    def predict(self, couplesTest, times):\n",
    "        pred = np.zeros(len(couplesTest))\n",
    "        for ind,c in enumerate(couplesTest):\n",
    "            pred[ind] = self.mu[times[ind]] + self.bu[c[0]][times[ind]] + self.bi[c[1]][times[ind]] + self.p[c[0]].dot(self.q[c[1]])[0][0]\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7.38218694634\n",
      "100 2.40772634594\n",
      "200 2.04236542863\n",
      "300 1.82604969996\n",
      "400 1.66328178972\n",
      "500 1.54301808579\n",
      "600 1.46656009831\n",
      "700 1.41664113998\n",
      "800 1.34577848033\n",
      "900 1.31440313527\n",
      "1000 1.27721477175\n",
      "1100 1.23938703736\n",
      "1200 1.21573236876\n",
      "1300 1.19182469973\n",
      "1400 1.16185918917\n",
      "1500 1.14505301985\n",
      "1600 1.12298569513\n",
      "1700 1.11434524534\n",
      "1800 1.09356609176\n",
      "1900 1.07566680629\n",
      "2000 1.06034517233\n",
      "2100 1.05073143452\n",
      "2200 1.03463633167\n",
      "2300 1.03351976881\n",
      "2400 1.00546051589\n",
      "2500 0.992230321881\n",
      "2600 0.989208130194\n",
      "2700 0.984631471197\n",
      "2800 0.97436331598\n",
      "2900 0.964001450879\n",
      "3000 0.951868125837\n",
      "3100 0.945676352715\n",
      "3200 0.945077924491\n",
      "3300 0.932378608056\n",
      "3400 0.928977810918\n",
      "3500 0.920597096203\n",
      "3600 0.911642060459\n",
      "3700 0.912624412397\n",
      "3800 0.919521952017\n",
      "3900 0.900349521843\n",
      "4000 0.894480867446\n",
      "4100 0.893062156648\n",
      "4200 0.884593363188\n",
      "4300 0.88223867308\n",
      "4400 0.876092385545\n",
      "4500 0.876136290141\n",
      "4600 0.878483382842\n",
      "4700 0.876169580905\n",
      "4800 0.866760822354\n",
      "4900 0.859895468965\n",
      "5000 0.850338348064\n",
      "5100 0.85571743359\n",
      "5200 0.849407737788\n",
      "5300 0.847267260961\n",
      "5400 0.835731883939\n",
      "5500 0.841226891573\n",
      "5600 0.837088237194\n",
      "5700 0.8404459521\n",
      "5800 0.834607475678\n",
      "5900 0.828627093808\n",
      "6000 0.834050067715\n",
      "6100 0.82856117335\n",
      "6200 0.827876055531\n",
      "6300 0.813718736384\n",
      "6400 0.809059847021\n",
      "6500 0.81837183669\n",
      "6600 0.809355230378\n",
      "6700 0.806925134967\n",
      "6800 0.804395881846\n",
      "6900 0.80172298359\n",
      "7000 0.801937920565\n",
      "7100 0.797798871076\n",
      "7200 0.798275227338\n",
      "7300 0.789095727854\n",
      "7400 0.786833163259\n",
      "7500 0.793360637668\n",
      "7600 0.787037464686\n",
      "7700 0.786088687621\n",
      "7800 0.77911985256\n",
      "7900 0.778189322613\n",
      "8000 0.773995802439\n",
      "8100 0.780493493387\n",
      "8200 0.77383987894\n",
      "8300 0.77097539607\n",
      "8400 0.768967911519\n",
      "8500 0.771793710608\n",
      "8600 0.760965927597\n",
      "8700 0.765171911144\n",
      "8800 0.758860829155\n",
      "8900 0.755063327997\n",
      "9000 0.764078860961\n",
      "9100 0.757917668422\n",
      "9200 0.756454060774\n",
      "9300 0.747950311723\n",
      "9400 0.744651527809\n",
      "9500 0.749038222961\n",
      "9600 0.75102525594\n",
      "9700 0.746027615877\n",
      "9800 0.73930917165\n",
      "9900 0.738899399746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:31: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "model5 = matrixFactorisationBiaisTemporel(10, alternate=0)\n",
    "model5.fit(trainUsers, trainItems, trainCouples, times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base 1M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadMovieLens1M(path='./data1m'):\n",
    "    # Get movie titles\n",
    "    movies={}\n",
    "    for line in open(path+'/movies.dat'):\n",
    "        id,title=line.split('::')[0:2]\n",
    "        movies[id]=title\n",
    "    # Load data\n",
    "    prefs={}\n",
    "    times={}\n",
    "    for line in open(path+'/ratings.dat'):\n",
    "        (user,movieid,rating,ts)=line.split('::')\n",
    "        prefs.setdefault(user,{})\n",
    "        prefs[user][movies[movieid]]=float(rating)\n",
    "        times.setdefault(user,{})\n",
    "        times[user][movies[movieid]]=float(ts)\n",
    "    return prefs, times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data, timestamps = loadMovieLens1M()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "couples = getCouplesUsersItems(data)\n",
    "\n",
    "trainCouples, testCouples = splitTrainTest(couples,.20)\n",
    "\n",
    "trainUsers = buildUsersDict(trainCouples)\n",
    "trainItems = buildItemsDict(trainCouples)\n",
    "\n",
    "toDel = []\n",
    "\n",
    "for i,c in enumerate(testCouples):\n",
    "    if not c[0] in trainUsers:\n",
    "        toDel.append(i)\n",
    "    elif not c[1] in trainItems:\n",
    "        toDel.append(i)\n",
    "\n",
    "testCouples = np.delete(testCouples, toDel, 0)\n",
    "\n",
    "testUsers  = buildUsersDict(testCouples)\n",
    "testItems  = buildItemsDict(testCouples)\n",
    "\n",
    "#print len(trainUsers), len(testUsers)\n",
    "#print len(trainItems), len(testItems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nbins = 5\n",
    "\n",
    "times = getTimeBins(couples, timestamps, nbins)\n",
    "ratings = np.array(np.array(couples)[:,2], float)\n",
    "plt.figure()\n",
    "for i in xrange(nbins):\n",
    "    histi = np.bincount(np.array(ratings[times==i], int))\n",
    "    plt.plot(1.* histi / histi.sum() , 'o-')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model6 = baselineMeanUsers()\n",
    "model6.fit(trainUsers)\n",
    "pred = model6.predict(testCouples)\n",
    "print \"erreur en test:\", ((pred - np.array(testCouples[:,2], float)) ** 2).mean()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model7 = baselineMeanItems()\n",
    "model7.fit(trainItems)\n",
    "pred = model7.predict(testCouples)\n",
    "print \"erreur en test:\", ((pred - np.array(testCouples[:,2], float)) ** 2).mean()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model8 = matrixFactorisation(10, alternate=0, maxIter=1000)\n",
    "model8.fit(trainUsers, trainItems, trainCouples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(model8.loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model8.predict(testCouples)\n",
    "print ((pred - np.array(testCouples[:,2], float)) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model9 = matrixFactorisationBiais(10, alternate=0)\n",
    "model9.fit(trainUsers, trainItems, trainCouples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(model9.loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model9.predict(testCouples)\n",
    "print ((pred - np.array(testCouples[:,2], float)) ** 2).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
