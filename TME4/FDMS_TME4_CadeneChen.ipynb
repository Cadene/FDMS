{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP4 - Filtrage Collaboratif\n",
    "\n",
    "L'objectif de ce TME est d'implémenter des méthodes de filtrage collaboratif.\n",
    "\n",
    "On utilisera les données Movie Lens 100k et Movie Lens 1M qui correspondent à deux bases de données de notes attribués par un ensemble d'utilisateurs sur des films, contenant respectivement 100 000 et 1 millions d'entrés.\n",
    "\n",
    "On s'intéressera en premier lieu à un modèle de factorisation de matrice simple sans biais, puis on incluera dans le modèle un biais par utilisateur et par film. Enfin, on implémentera un modèle tenant compte du fait que ces biais peuvent évoluer dans le temps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données\n",
    "\n",
    "Les fonctions pour charger les bases Movie Lens 100k et Movie Lens 1M.\n",
    "On récupère un dictionnaire pour les scores et un dictionnaire pour les dates.\n",
    "Le première index de ces dictionnaires est l'identifiant de l'utilisateur, et le second les films notés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loadMovieLens(path='./data100k'):\n",
    "    # Get movie titles\n",
    "    movies={}\n",
    "    for line in open(path+'/u.item'):\n",
    "        (id,title)=line.split('|')[0:2]\n",
    "        movies[id]=title\n",
    "    # Load data\n",
    "    prefs={} # Un dictionnaire User > Item > Rating\n",
    "    times={} # Un dictionnaire User > Item > Timestamps\n",
    "    for line in open(path+'/u.data'):\n",
    "        (user,movieid,rating,ts)=line.split('\\t')\n",
    "        prefs.setdefault(user,{})\n",
    "        prefs[user][movies[movieid]]=float(rating)\n",
    "        times.setdefault(user,{})\n",
    "        times[user][movies[movieid]]=float(ts)\n",
    "    return prefs, times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadMovieLens1M(path='./data1m'):\n",
    "    # Get movie titles\n",
    "    movies={}\n",
    "    for line in open(path+'/movies.dat'):\n",
    "        id,title=line.split('::')[0:2]\n",
    "        movies[id]=title\n",
    "    # Load data\n",
    "    prefs={}\n",
    "    times={}\n",
    "    for line in open(path+'/ratings.dat'):\n",
    "        (user,movieid,rating,ts)=line.split('::')\n",
    "        prefs.setdefault(user,{})\n",
    "        prefs[user][movies[movieid]]=float(rating)\n",
    "        times.setdefault(user,{})\n",
    "        times[user][movies[movieid]]=float(ts)\n",
    "    return prefs, times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Représentations des données\n",
    "\n",
    "Les matrices des scores Utilisateurs/Films sont des matrices de grandes dimensions mais sparses.\n",
    "Afin de les manipuler efficacement, on emploiera 3 représentations différentes en même temps:\n",
    "- Le dictionnaire des scores par utilisateurs: User > Item > Value\n",
    "- Le dictionnaire des scores par films: Item > User > Value \n",
    "- La liste des triplets [User, Item, Value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recupère une représentation des données sous la forme triplets [user, item, value] a partir d'un dictionnaire [User > item > value]\n",
    "def getCouplesUsersItems(data):\n",
    "    couples = []\n",
    "    for u in data.keys():\n",
    "        for i in data[u].keys():\n",
    "            couples.append([u,i,data[u][i]])\n",
    "    return couples\n",
    "\n",
    "# Construit le dictionnaire des utilisateurs a partir des triplets [user, item, note]\n",
    "def buildUsersDict(couples):\n",
    "    dicUsers = {}\n",
    "    for c in couples:\n",
    "        if not c[0] in dicUsers.keys():\n",
    "            dicUsers[c[0]] = {}\n",
    "        dicUsers[c[0]][c[1]] = float(c[2])\n",
    "    return dicUsers\n",
    "\n",
    "# Construit le dictionnaire des objets a partir des triplets [user, item, note]\n",
    "def buildItemsDict(couples):\n",
    "    dicItems = {}\n",
    "    for c in couples:\n",
    "        if not c[1] in dicItems:\n",
    "            dicItems[c[1]] = {}\n",
    "        dicItems[c[1]][c[0]] = float(c[2])\n",
    "    return dicItems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données de temps\n",
    "\n",
    "Afin d'exploiter les données temporelles, on discrétise le temps en bins et on construit un vecteur qui a chaque triplets [user, item, value] associe le bins temporel correspondant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTimeBins(couples, timedic, nbins):\n",
    "    timestamps = np.zeros(len(couples))\n",
    "    for i,c in enumerate(couples):\n",
    "        timestamps[i] = timedic[c[0]][c[1]]\n",
    "    time_bins = np.linspace(np.min(timestamps), np.max(timestamps), nbins+1)\n",
    "    times = np.zeros(len(couples),int)\n",
    "    for i in xrange(1,len(time_bins)):\n",
    "        times = times + (timestamps > time_bins[i])\n",
    "    return times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation des données en Train / Test\n",
    "\n",
    "Pour pouvoir séparer les données en ensembles de Train et de Test, on utilisera la liste des triplets [User, Item, Scores]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split l'ensemble des triplets [user, item, note] en testProp% données de test et (1 - testProp) données de train\n",
    "def splitTrainTest(couples,testProp):\n",
    "    perm = np.random.permutation(couples)\n",
    "    splitIndex = int(testProp * len(couples))\n",
    "    return perm[splitIndex:], perm[:splitIndex]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèles\n",
    "\n",
    "## Baseline 1 : Moyenne par utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class baselineMeanUsers():\n",
    "    def __init__(self):\n",
    "        self.mean = {}\n",
    "    def fit(self, dataUsers):\n",
    "        self.mean = {}\n",
    "        for u in dataUsers.keys():\n",
    "            self.mean[u] = 0\n",
    "            for i in dataUsers[u].keys():\n",
    "                self.mean[u] = self.mean[u] + dataUsers[u][i]\n",
    "            self.mean[u] = self.mean[u] / len(dataUsers[u])\n",
    "    def predict(self, couplesTest):\n",
    "        pred = np.zeros(len(couplesTest))\n",
    "        for ind,c in enumerate(couplesTest):\n",
    "            pred[ind] = self.mean[c[0]]\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 2 : Moyenne par item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class baselineMeanItems():\n",
    "    def __init__(self):            \n",
    "        self.mean = {}\n",
    "    def fit(self, dataItems):\n",
    "        self.mean = {}\n",
    "        for i in dataItems.keys():\n",
    "            self.mean[i] = 0\n",
    "            for u in dataItems[i].keys():\n",
    "                self.mean[i] = self.mean[i] + dataItems[i][u]\n",
    "            self.mean[i] = self.mean[i] / len(dataItems[i])\n",
    "    def predict(self, couplesTest):\n",
    "        pred = np.zeros(len(couplesTest))\n",
    "        for ind,c in enumerate(couplesTest):\n",
    "            pred[ind] = self.mean[c[1]]\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorisation de Matrices sans biais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class matrixFactorisation():\n",
    "    def __init__(self, k, lambd=0.2, eps=1e-5, maxIter=2000, alternate=0):\n",
    "        self.k = k\n",
    "        self.lambd = lambd\n",
    "        self.eps = eps\n",
    "        self.maxIter = maxIter\n",
    "        self.alternate = alternate #Pour l'optimisation alternée: 0 si non.\n",
    "    def fit(self, dataUsers, dataItems, couples):\n",
    "        self.p = {}\n",
    "        self.q = {}\n",
    "        self.loss = []\n",
    "        #Choix du paramètre a optimisé en cas d'optimisation alternée\n",
    "        optimP = True\n",
    "        optimQ = (self.alternate == 0)\n",
    "        for i in xrange(self.maxIter):\n",
    "            loss = 0\n",
    "            for j in xrange(len(couples)):\n",
    "                #choix d'une entrée aléatoire\n",
    "                r = np.random.randint(len(couples)) \n",
    "                user = couples[r][0]\n",
    "                item = couples[r][1]\n",
    "                # initialisation des nouveaux vecteurs p et q\n",
    "                if not user in self.p:\n",
    "                    self.p[user] = np.random.rand(1,self.k)\n",
    "                if not item in self.q:\n",
    "                    self.q[item] = np.random.rand(self.k,1)\n",
    "                # Descente de gradient\n",
    "                tmp = dataUsers[user][item] - self.p[user].dot(self.q[item])[0][0]\n",
    "                if (optimP):\n",
    "                    self.p[user] = (1 - self.lambd * self.eps) * self.p[user] + self.eps * 2 * tmp * self.q[item].transpose()\n",
    "                if (optimQ):\n",
    "                    self.q[item] = (1 - self.lambd * self.eps) * self.q[item] + self.eps * 2 * tmp * self.p[user].transpose()\n",
    "                loss = loss + tmp*tmp #(Sans le terme de régularisation)\n",
    "            self.loss.append(loss)\n",
    "            # Optimisation alternée\n",
    "            if (self.alternate != 0):\n",
    "                if (i % self.alternate == 0):\n",
    "                    optimP = optimQ\n",
    "                    optimQ = 1 - optimQ\n",
    "                    print i, loss / len(couples)\n",
    "            else:\n",
    "                if (i % 100 == 0):\n",
    "                    print i, loss / len(couples)\n",
    "    def predict(self, couplesTest):\n",
    "        pred = np.zeros(len(couplesTest))\n",
    "        for ind,c in enumerate(couplesTest):\n",
    "            pred[ind] = self.p[c[0]].dot(self.q[c[1]])[0][0]\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorisation de Matrices avec biais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Comme matrixFactorisation() avec plus de paramètres\n",
    "class matrixFactorisationBiais():\n",
    "    def __init__(self, k, lambd=0.2, eps=1e-5, maxIter=10000, alternate=0):\n",
    "        self.k = k\n",
    "        self.lambd = lambd\n",
    "        self.eps = eps\n",
    "        self.maxIter = maxIter\n",
    "        self.alternate = alternate\n",
    "    def fit(self, dataUsers, dataItems, couples):\n",
    "        self.p = {}\n",
    "        self.q = {}\n",
    "        self.bu = {}\n",
    "        self.bi = {}\n",
    "        self.mu = np.random.random() * 2 - 1\n",
    "        self.loss = []\n",
    "        optimP = True\n",
    "        optimQ = (self.alternate == 0)\n",
    "        for i in xrange(self.maxIter):\n",
    "            loss = 0\n",
    "            for j in xrange(len(couples)):\n",
    "                r = np.random.randint(len(couples))\n",
    "                user = couples[r][0]\n",
    "                item = couples[r][1]\n",
    "                if not user in self.p:\n",
    "                    self.p[user] = np.random.rand(1,self.k) * 2 - 1\n",
    "                    self.bu[user] = np.random.rand() * 2 - 1\n",
    "                if not item in self.q:\n",
    "                    self.q[item] = np.random.rand(self.k,1) * 2 - 1\n",
    "                    self.bi[item] = np.random.rand() * 2 - 1\n",
    "                tmp = dataUsers[user][item] - (self.mu + self.bi[item] + self.bu[user] + self.p[user].dot(self.q[item])[0][0])\n",
    "                if (optimP):\n",
    "                    self.p[user] = (1 - self.lambd * self.eps) * self.p[user] + self.eps * 2 * tmp * self.q[item].transpose()\n",
    "                    self.bu[user] = (1 - self.lambd * self.eps) * self.bu[user] + self.eps * 2 * tmp\n",
    "                if (optimQ):\n",
    "                    self.q[item] = (1 - self.lambd * self.eps) * self.q[item] + self.eps * 2 * tmp * self.p[user].transpose()\n",
    "                    self.bi[item] = (1 - self.lambd * self.eps) * self.bi[item] + self.eps * 2 * tmp\n",
    "                self.mu = (1 - self.lambd * self.eps) * self.mu + self.eps * 2 * tmp\n",
    "                loss = loss + tmp*tmp\n",
    "            self.loss.append(loss)\n",
    "            if (self.alternate != 0):\n",
    "                if (i % self.alternate == 0):\n",
    "                    optimP = optimQ\n",
    "                    optimQ = 1 - optimQ\n",
    "                    print i, loss / len(couples)\n",
    "            else:\n",
    "                if (i % 100 == 0):\n",
    "                    print i, loss / len(couples)\n",
    "    def predict(self, couplesTest):\n",
    "        pred = np.zeros(len(couplesTest))\n",
    "        for ind,c in enumerate(couplesTest):\n",
    "            pred[ind] = self.mu + self.bu[c[0]] + self.bi[c[1]] + self.p[c[0]].dot(self.q[c[1]])[0][0]\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorisation de Matrices avec biais temporel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class matrixFactorisationBiaisTemporel():\n",
    "    def __init__(self, k=10, ntimes=5, lambd=0.2, eps=1e-5, maxIter=10000, alternate=0):\n",
    "        self.k = k\n",
    "        self.ntimes = ntimes\n",
    "        self.lambd = lambd\n",
    "        self.eps = eps\n",
    "        self.maxIter = maxIter\n",
    "        self.alternate = alternate\n",
    "    def fit(self, dataUsers, dataItems, couples, times):\n",
    "        self.p = {}\n",
    "        self.q = {}\n",
    "        self.bu = {}\n",
    "        self.bi = {}\n",
    "        self.mu = np.random.rand(self.ntimes) * 2 - 1\n",
    "        self.loss = []\n",
    "        optimP = True\n",
    "        optimQ = (self.alternate == 0)\n",
    "        for i in xrange(self.maxIter):\n",
    "            loss = 0\n",
    "            for j in xrange(len(couples)):\n",
    "                r = np.random.randint(len(couples))\n",
    "                user = couples[r][0]\n",
    "                item = couples[r][1]\n",
    "                time = times[r]\n",
    "                if not user in self.p:\n",
    "                    self.p[user] = np.random.rand(1,self.k) * 2 - 1\n",
    "                    self.bu[user] = np.random.rand(self.ntimes) * 2 - 1\n",
    "                if not item in self.q:\n",
    "                    self.q[item] = np.random.rand(self.k,1) * 2 - 1\n",
    "                    self.bi[item] = np.random.rand(self.ntimes) * 2 - 1\n",
    "                tmp = dataUsers[user][item] - (self.mu[time] + self.bi[item][time] + self.bu[user][time] + self.p[user].dot(self.q[item])[0][0])\n",
    "                if (optimP):\n",
    "                    self.p[user] = (1 - self.lambd * self.eps) * self.p[user] + self.eps * 2 * tmp * self.q[item].transpose()\n",
    "                    self.bu[user][time] = (1 - self.lambd * self.eps) * self.bu[user][time] + self.eps * 2 * tmp\n",
    "                if (optimQ):\n",
    "                    self.q[item] = (1 - self.lambd * self.eps) * self.q[item] + self.eps * 2 * tmp * self.p[user].transpose()\n",
    "                    self.bi[item][time] = (1 - self.lambd * self.eps) * self.bi[item][time] + self.eps * 2 * tmp\n",
    "                self.mu[time] = (1 - self.lambd * self.eps) * self.mu[time] + self.eps * 2 * tmp\n",
    "                loss = loss + tmp*tmp #Sans régularisation\n",
    "            self.loss.append(loss)\n",
    "            if (self.alternate != 0):\n",
    "                if (i % self.alternate == 0):\n",
    "                    optimP = optimQ\n",
    "                    optimQ = 1 - optimQ\n",
    "                    print i, loss / len(couples)\n",
    "            else:\n",
    "                if (i % 100 == 0):\n",
    "                    print i, loss / len(couples)\n",
    "    def predict(self, couplesTest, times):\n",
    "        pred = np.zeros(len(couplesTest))\n",
    "        for ind,c in enumerate(couplesTest):\n",
    "            pred[ind] = self.mu[times[ind]] + self.bu[c[0]][times[ind]] + self.bi[c[1]][times[ind]] + self.p[c[0]].dot(self.q[c[1]])[0][0]\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests les données Movie Lens 100k\n",
    "\n",
    "## Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Chargement\n",
    "data, timestamps = loadMovieLens()\n",
    "\n",
    "# Récupérer la représentation en liste de triplets\n",
    "couples = getCouplesUsersItems(data)\n",
    "\n",
    "# La séparer en ensemble d'apprentissage et de test\n",
    "trainCouples, testCouples = splitTrainTest(couples,.20)\n",
    "\n",
    "# Reconstruire les dictionnaires pour l'ensemble d'apprentissage\n",
    "trainUsers = buildUsersDict(trainCouples)\n",
    "trainItems = buildItemsDict(trainCouples)\n",
    "\n",
    "# Supprimer de l'ensemble de test les éléments inconnus en apprentissage\n",
    "toDel = []\n",
    "for i,c in enumerate(testCouples):\n",
    "    if not c[0] in trainUsers:\n",
    "        toDel.append(i)\n",
    "    elif not c[1] in trainItems:\n",
    "        toDel.append(i)\n",
    "testCouples = np.delete(testCouples, toDel, 0)\n",
    "\n",
    "# Reconstruire les dictionnaires pour l'ensemble de test\n",
    "testUsers  = buildUsersDict(testCouples)\n",
    "testItems  = buildItemsDict(testCouples)\n",
    "\n",
    "# Récupérer les vecteurs des temps\n",
    "nbins = 5\n",
    "times = getTimeBins(couples, timestamps, nbins)\n",
    "trainTimes = getTimeBins(trainCouples, timestamps, nbins)\n",
    "testTimes = getTimeBins(testCouples, timestamps, nbins)\n",
    "\n",
    "# taille des données\n",
    "#print len(trainUsers), len(testUsers)\n",
    "#print len(trainItems), len(testItems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erreur en test: 1.08839474696\n"
     ]
    }
   ],
   "source": [
    "model1 = baselineMeanUsers()\n",
    "model1.fit(trainUsers)\n",
    "pred = model1.predict(testCouples)\n",
    "print \"erreur en test:\", ((pred - np.array(testCouples[:,2], float)) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erreur en test: 1.03859106198\n"
     ]
    }
   ],
   "source": [
    "model2 = baselineMeanItems()\n",
    "model2.fit(trainItems)\n",
    "pred = model2.predict(testCouples)\n",
    "print \"erreur en test:\", ((pred - np.array(testCouples[:,2], float)) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorisation matricielle sans biais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.829537706\n",
      "100 1.30712001798\n",
      "200 1.07948970774\n",
      "300 0.997287439085\n",
      "400 0.952657605705\n",
      "500 0.917643772482\n",
      "600 0.89365902144\n",
      "700 0.888028692502\n",
      "800 0.869048170694\n",
      "900 0.868529460105\n",
      "1000 0.858853615837\n",
      "1100 0.863836741598\n",
      "1200 0.852722256483\n",
      "1300 0.842192524637\n",
      "1400 0.841983968252\n",
      "1500 0.844243257703\n",
      "1600 0.837896616117\n",
      "1700 0.837744282998\n",
      "1800 0.832008944357\n",
      "1900 0.83920613112\n"
     ]
    }
   ],
   "source": [
    "model3 = matrixFactorisation(10, alternate=0)\n",
    "model3.fit(trainUsers, trainItems, trainCouples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(model3.loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur de test: 0.909580818424\n"
     ]
    }
   ],
   "source": [
    "pred = model3.predict(testCouples)\n",
    "print \"Erreur de test:\", ((pred - np.array(testCouples[:,2], float)) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorisation matricielle avec biais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7.84879153329\n",
      "100 2.20841845373\n",
      "200 1.78135161261\n",
      "300 1.50665884754\n",
      "400 1.36179780473\n",
      "500 1.27271620043\n",
      "600 1.18725411492\n",
      "700 1.13627534893\n",
      "800 1.08727524392\n",
      "900 1.05073590425\n",
      "1000 1.01654162391\n",
      "1100 1.00560542752\n",
      "1200 0.97646470343\n",
      "1300 0.967124816417\n",
      "1400 0.950623023452\n",
      "1500 0.94110060945\n",
      "1600 0.928282231649\n",
      "1700 0.913576022519\n",
      "1800 0.90368654631\n",
      "1900 0.889919122869\n",
      "2000 0.886632345112\n",
      "2100 0.87637080938\n",
      "2200 0.879517708617\n",
      "2300 0.872767670014\n",
      "2400 0.863631577612\n",
      "2500 0.853651927641\n",
      "2600 0.849095197608\n",
      "2700 0.855620811393\n",
      "2800 0.843541206755\n",
      "2900 0.844477373661\n",
      "3000 0.841569307323\n",
      "3100 0.842851965166\n",
      "3200 0.833419184501\n",
      "3300 0.824305787357\n",
      "3400 0.832219602661\n",
      "3500 0.825525993355\n",
      "3600 0.824484381541\n",
      "3700 0.816336008193\n",
      "3800 0.815159277787\n",
      "3900 0.814879026143\n",
      "4000 0.813612289994\n",
      "4100 0.813574241683\n",
      "4200 0.802972958589\n",
      "4300 0.811059457145\n",
      "4400 0.804668565967\n",
      "4500 0.800480942454\n",
      "4600 0.803039122674\n",
      "4700 0.798049443498\n",
      "4800 0.797483731818\n",
      "4900 0.796329706711\n",
      "5000 0.789174918466\n",
      "5100 0.791177143524\n",
      "5200 0.786608210483\n",
      "5300 0.788704131071\n",
      "5400 0.784770640646\n",
      "5500 0.781415889645\n",
      "5600 0.788106017931\n",
      "5700 0.780995331137\n",
      "5800 0.768241354766\n",
      "5900 0.772388355041\n",
      "6000 0.770515710955\n",
      "6100 0.778211415174\n",
      "6200 0.774700133019\n",
      "6300 0.779695322178\n",
      "6400 0.766843838768\n",
      "6500 0.766804444781\n",
      "6600 0.761505748972\n",
      "6700 0.765190115456\n",
      "6800 0.765347829132\n",
      "6900 0.764181275541\n",
      "7000 0.755660379782\n",
      "7100 0.756277149286\n",
      "7200 0.758423586497\n",
      "7300 0.758824592247\n",
      "7400 0.755913434182\n",
      "7500 0.74682818907\n",
      "7600 0.748383203179\n",
      "7700 0.746113895937\n",
      "7800 0.739821600998\n",
      "7900 0.748992464971\n",
      "8000 0.744560945647\n",
      "8100 0.747488962401\n",
      "8200 0.74483471385\n",
      "8300 0.741946324107\n",
      "8400 0.737835278301\n",
      "8500 0.733317991715\n",
      "8600 0.737173402373\n",
      "8700 0.742342540094\n",
      "8800 0.731533756674\n",
      "8900 0.728225962676\n",
      "9000 0.728983224634\n",
      "9100 0.730584312803\n",
      "9200 0.726048811083\n",
      "9300 0.724669003038\n",
      "9400 0.722043913633\n",
      "9500 0.729239252944\n",
      "9600 0.721099577929\n",
      "9700 0.718941520324\n",
      "9800 0.723550634396\n",
      "9900 0.713612781405\n"
     ]
    }
   ],
   "source": [
    "model4 = matrixFactorisationBiais(10, alternate=0)\n",
    "model4.fit(trainUsers, trainItems, trainCouples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(model4.loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.90047122114\n"
     ]
    }
   ],
   "source": [
    "pred = model4.predict(testCouples)\n",
    "print ((pred - np.array(testCouples[:,2], float)) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biais Temporel\n",
    "\n",
    "### Visualisition des notes en fonction du temps\n",
    "![alt text](./ratingsByTime1k.png \"Distribution des scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings = np.array(np.array(couples)[:,2], float)\n",
    "plt.figure()\n",
    "for i in xrange(nbins):\n",
    "    histi = np.bincount(np.array(ratings[times==i], int))\n",
    "    plt.plot(1.* histi / histi.sum() , 'o-')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultats (pas bon, a refaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.67272772294\n",
      "100 2.39851598656\n",
      "200 2.03459234926\n",
      "300 1.81139905907\n",
      "400 1.66860929545\n",
      "500 1.55222519475\n",
      "600 1.4740954684\n",
      "700 1.40879194473\n",
      "800 1.36541067006\n",
      "900 1.30120495766\n",
      "1000 1.26982794492\n",
      "1100 1.23715478364\n",
      "1200 1.21515926539\n",
      "1300 1.18462986766\n",
      "1400 1.16283237634\n",
      "1500 1.13765379581\n",
      "1600 1.1211176562\n",
      "1700 1.10614780981\n",
      "1800 1.07874680564\n",
      "1900 1.06609699254\n",
      "2000 1.05368110585\n",
      "2100 1.0438793476\n",
      "2200 1.02470072182\n",
      "2300 1.01067526082\n",
      "2400 1.01651111078\n",
      "2500 1.0008570694\n",
      "2600 0.983412318075\n",
      "2700 0.979243005145\n",
      "2800 0.972186045903\n",
      "2900 0.963801902146\n",
      "3000 0.959951237108\n",
      "3100 0.946482006126\n",
      "3200 0.942638702669\n",
      "3300 0.93229056953\n",
      "3400 0.922386182976\n",
      "3500 0.922667408037\n",
      "3600 0.916931268408\n",
      "3700 0.906495457662\n",
      "3800 0.904733177419\n",
      "3900 0.902645520406\n",
      "4000 0.894787529597\n",
      "4100 0.891496157402\n",
      "4200 0.89578399219\n",
      "4300 0.886638650815\n",
      "4400 0.884556023075\n",
      "4500 0.876389370103\n",
      "4600 0.867495263732\n",
      "4700 0.868984186507\n",
      "4800 0.862418832999\n",
      "4900 0.850179707736\n",
      "5000 0.852969600596\n",
      "5100 0.852208608488\n",
      "5200 0.846650303333\n",
      "5300 0.846289576855\n",
      "5400 0.839768250392\n",
      "5500 0.831412649761\n",
      "5600 0.836638762112\n",
      "5700 0.830476340006\n",
      "5800 0.830178058074\n",
      "5900 0.830774860831\n",
      "6000 0.828432940449\n",
      "6100 0.813090128193\n",
      "6200 0.822955781755\n",
      "6300 0.81414615017\n",
      "6400 0.808644146956\n",
      "6500 0.814571356045\n",
      "6600 0.81554255502\n",
      "6700 0.797665194117\n",
      "6800 0.801984974513\n",
      "6900 0.801794820891\n",
      "7000 0.803140937687\n",
      "7100 0.79167493419\n",
      "7200 0.790222803366\n",
      "7300 0.796698509299\n",
      "7400 0.790533559645\n",
      "7500 0.791513288387\n",
      "7600 0.785242433582\n",
      "7700 0.779860588315\n",
      "7800 0.781165142577\n",
      "7900 0.781500541083\n",
      "8000 0.775376918918\n",
      "8100 0.780317270755\n",
      "8200 0.776038846817\n",
      "8300 0.770425873698\n",
      "8400 0.765250451381\n",
      "8500 0.759341978556\n",
      "8600 0.764529856648\n",
      "8700 0.759307843378\n",
      "8800 0.756310261439\n",
      "8900 0.758876404983\n",
      "9000 0.756613703712\n",
      "9100 0.757647732237\n",
      "9200 0.758565742623\n",
      "9300 0.755484656425\n",
      "9400 0.746118439565\n",
      "9500 0.744559034914\n",
      "9600 0.74939645451\n",
      "9700 0.751320449894\n",
      "9800 0.744682172901\n",
      "9900 0.746647927923\n"
     ]
    }
   ],
   "source": [
    "model5 = matrixFactorisationBiaisTemporel(10, alternate=0)\n",
    "model5.fit(trainUsers, trainItems, trainCouples, trainTimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(model5.loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.941643072909\n"
     ]
    }
   ],
   "source": [
    "pred = model5.predict(testCouples, testTimes)\n",
    "print ((pred - np.array(testCouples[:,2], float)) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Experiences sur les données Movie Lens 1M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Chargement\n",
    "data, timestamps = loadMovieLens1M()\n",
    "\n",
    "# Récupérer la représentation en liste de triplets\n",
    "couples = getCouplesUsersItems(data)\n",
    "\n",
    "# Séparer en ensemble d'apprentissage et de test\n",
    "trainCouples, testCouples = splitTrainTest(couples,.20)\n",
    "\n",
    "# Reconstruire les dictionnaires pour l'ensemble d'apprentissage\n",
    "trainUsers = buildUsersDict(trainCouples)\n",
    "trainItems = buildItemsDict(trainCouples)\n",
    "\n",
    "# Supprimer de l'ensemble de test les éléments inconnus en apprentissage\n",
    "toDel = []\n",
    "for i,c in enumerate(testCouples):\n",
    "    if not c[0] in trainUsers:\n",
    "        toDel.append(i)\n",
    "    elif not c[1] in trainItems:\n",
    "        toDel.append(i)\n",
    "testCouples = np.delete(testCouples, toDel, 0)\n",
    "\n",
    "# Reconstruire les dictionnaires pour l'ensemble de test\n",
    "testUsers  = buildUsersDict(testCouples)\n",
    "testItems  = buildItemsDict(testCouples)\n",
    "\n",
    "# Récupérer les vecteurs des temps\n",
    "nbins = 5\n",
    "times = getTimeBins(couples, timestamps, nbins)\n",
    "trainTimes = getTimeBins(trainCouples, timestamps, nbins)\n",
    "testTimes = getTimeBins(testCouples, timestamps, nbins)\n",
    "\n",
    "# taille des données\n",
    "#print len(trainUsers), len(testUsers)\n",
    "#print len(trainItems), len(testItems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erreur en test: 1.07459570403\n"
     ]
    }
   ],
   "source": [
    "model6 = baselineMeanUsers()\n",
    "model6.fit(trainUsers)\n",
    "pred = model6.predict(testCouples)\n",
    "print \"erreur en test:\", ((pred - np.array(testCouples[:,2], float)) ** 2).mean()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erreur en test: 0.958876325654\n"
     ]
    }
   ],
   "source": [
    "model7 = baselineMeanItems()\n",
    "model7.fit(trainItems)\n",
    "pred = model7.predict(testCouples)\n",
    "print \"erreur en test:\", ((pred - np.array(testCouples[:,2], float)) ** 2).mean()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorisation Matricielle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.85630500372\n",
      "100 0.989208053185\n",
      "200 0.894268607039\n",
      "300 0.859435186046\n",
      "400 0.843744226415\n",
      "500 0.834776300235\n",
      "600 0.829587454159\n",
      "700 0.826814746078\n",
      "800 0.820488518828\n",
      "900 0.820793261528\n"
     ]
    }
   ],
   "source": [
    "model8 = matrixFactorisation(10, alternate=0, maxIter=1000)\n",
    "model8.fit(trainUsers, trainItems, trainCouples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(model8.loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.848198539785\n"
     ]
    }
   ],
   "source": [
    "pred = model8.predict(testCouples)\n",
    "print ((pred - np.array(testCouples[:,2], float)) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorisation Matricielle avec biais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.47218672534\n",
      "100 1.53995091541\n",
      "200 1.22517433171\n",
      "300 1.09549293316\n",
      "400 1.02389512199\n",
      "500 0.978845337117\n",
      "600 0.94824016809\n",
      "700 0.925148099365\n",
      "800 0.90515288607\n",
      "900 0.894416953748\n",
      "1000 0.88204288694\n",
      "1100 0.871257580652\n",
      "1200 0.864077916237\n",
      "1300 0.858869586043\n",
      "1400 0.852355995456\n",
      "1500 0.847843742846\n",
      "1600 0.841015305358\n",
      "1700 0.836168926899\n",
      "1800 0.835827627137\n",
      "1900 0.832978355848\n"
     ]
    }
   ],
   "source": [
    "model9 = matrixFactorisationBiais(10, alternate=0, maxIter=2000)\n",
    "model9.fit(trainUsers, trainItems, trainCouples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.880414019261\n"
     ]
    }
   ],
   "source": [
    "pred = model9.predict(testCouples)\n",
    "print ((pred - np.array(testCouples[:,2], float)) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(model9.loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorisation de Matrices avec biais temporel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model10 = matrixFactorisationBiaisTemporel(10, alternate=0, maxIter=2000)\n",
    "model10.fit(trainUsers, trainItems, trainCouples, trainTimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(model10.loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model10.predict(testCouples, testTimes)\n",
    "print ((pred - np.array(testCouples[:,2], float)) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
