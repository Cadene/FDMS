{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP4 - Filtrage Collaboratif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import BaseEstimator,ClassifierMixin\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loadMovieLens(path='./data100k'):\n",
    "  # Get movie titles\n",
    "  movies={}\n",
    "  for line in open(path+'/u.item'):\n",
    "    (id,title)=line.split('|')[0:2]\n",
    "    movies[id]=title\n",
    "  # Load data\n",
    "  prefs={}\n",
    "  for line in open(path+'/u.data'):\n",
    "    (user,movieid,rating,ts)=line.split('\\t')\n",
    "    prefs.setdefault(user,{})\n",
    "    prefs[user][movies[movieid]]=float(rating)\n",
    "  return prefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = loadMovieLens()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparation en données de Train et de Test\n",
    "\n",
    "Pour pouvoir séparer les données en ensembles de Train et de Test, on construit la liste des couples (Utilisateurs, Objets) dont on connait les scores.\n",
    "On extrait ensuite aléatoirement une portion (20%) de ces couples pour les données de test, et le reste sera utilisé en apprentissage.\n",
    "\n",
    "Comme on ne souhaite ne pas évaluer les objets et les utilisateurs qui n'ont jamais été rencontré en apprentissage, on retire les couples correspondants de l'ensemble de test.\n",
    "\n",
    "Il faut ensuite a partir de ces couples reconstruire le dictionnaire qui pour chaque utilisateur donne les objets qu'il a noté, ainsi que le dictionnaire qui pour chaque objet donne les utilisateurs qui l'ont noté."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getCouplesUsersItems(data):\n",
    "    couples = []\n",
    "    for u in data.keys():\n",
    "        for i in data[u].keys():\n",
    "            couples.append([u,i])\n",
    "    return couples\n",
    "\n",
    "def splitTrainTest(couples,testProp):\n",
    "    perm = np.random.permutation(couples)\n",
    "    splitIndex = int(testProp * len(couples))\n",
    "    return perm[splitIndex:], perm[:splitIndex]\n",
    "\n",
    "def buildUsersDict(data,couples=None):\n",
    "    if (couples == None):\n",
    "        couples = getCouplesUsersItems(data)\n",
    "    dicUsers = {}\n",
    "    for c in couples:\n",
    "        if not c[0] in dicUsers.keys():\n",
    "            dicUsers[c[0]] = {}\n",
    "        dicUsers[c[0]][c[1]] = data[c[0]][c[1]]\n",
    "    return dicUsers\n",
    "\n",
    "def buildItemsDict(data,couples=None):\n",
    "    if (couples == None):\n",
    "        couples = getCouplesUsersItems(data)\n",
    "    dicItems = {}\n",
    "    for c in couples:\n",
    "        if not c[1] in dicItems:\n",
    "            dicItems[c[1]] = {}\n",
    "        dicItems[c[1]][c[0]] = data[c[0]][c[1]]\n",
    "    return dicItems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "couples = getCouplesUsersItems(data)\n",
    "\n",
    "trainCouples, testCouples = splitTrainTest(couples,.20)\n",
    "\n",
    "trainUsers = buildUsersDict(data, trainCouples)\n",
    "trainItems = buildItemsDict(data, trainCouples)\n",
    "\n",
    "toDel = []\n",
    "\n",
    "for i,c in enumerate(testCouples):\n",
    "    if not c[0] in trainUsers:\n",
    "        toDel.append(i)\n",
    "    elif not c[1] in trainItems:\n",
    "        toDel.append(i)\n",
    "\n",
    "testCouples = np.delete(testCouples, toDel, 0)\n",
    "\n",
    "testUsers  = buildUsersDict(data, testCouples)\n",
    "testItems  = buildItemsDict(data, testCouples)\n",
    "\n",
    "#print len(trainUsers), len(testUsers)\n",
    "#print len(trainItems), len(testItems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 1 : Moyenne par utilisateur\n",
    "\n",
    "Ce modèle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class baselineMeanUsers(BaseEstimator,ClassifierMixin):\n",
    "    def __init__(self):            \n",
    "        self.mean = {}\n",
    "    def fit(self, dataUsers):\n",
    "        self.mean = {}\n",
    "        for u in dataUsers.keys():\n",
    "            self.mean[u] = 0\n",
    "            for i in dataUsers[u].keys():\n",
    "                self.mean[u] = self.mean[u] + dataUsers[u][i]\n",
    "            self.mean[u] = self.mean[u] / len(dataUsers[u])\n",
    "    def predict(self, couplesTest):\n",
    "        pred = np.zeros(len(couplesTest))\n",
    "        for ind,c in enumerate(couplesTest):\n",
    "            pred[ind] = self.mean[c[0]]\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.87795276  3.95505618  3.95950156 ...,  3.9375      3.75824176\n",
      "  3.57894737]\n"
     ]
    }
   ],
   "source": [
    "model1 = baselineMeanUsers()\n",
    "model1.fit(trainUsers)\n",
    "pred = model1.predict(testCouples)\n",
    "print pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 2 : Moyenne par item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class baselineMeanItems(BaseEstimator,ClassifierMixin):\n",
    "    def __init__(self):            \n",
    "        self.mean = {}\n",
    "    def fit(self, dataItems):\n",
    "        self.mean = {}\n",
    "        for i in dataItems.keys():\n",
    "            self.mean[i] = 0\n",
    "            for u in dataItems[i].keys():\n",
    "                self.mean[i] = self.mean[i] + dataItems[i][u]\n",
    "            self.mean[i] = self.mean[i] / len(dataItems[i])\n",
    "    def predict(self, couplesTest):\n",
    "        pred = np.zeros(len(couplesTest))\n",
    "        for ind,c in enumerate(couplesTest):\n",
    "            pred[ind] = self.mean[c[1]]\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.81108312  3.26950355  2.84375    ...,  3.92405063  4.1         3.54491018]\n"
     ]
    }
   ],
   "source": [
    "model2 = baselineMeanItems()\n",
    "model2.fit(trainItems)\n",
    "pred = model2.predict(testCouples)\n",
    "print pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorisation de Matrices\n",
    "\n",
    "Faire varier N la taille de l'espace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class matrixFactorisation():\n",
    "    def __init__(self, k, lambd=0.1, eps=1e-5, maxIter=1000):\n",
    "        self.k = k\n",
    "        self.lambd = lambd\n",
    "        self.eps = eps\n",
    "        self.maxIter = maxIter\n",
    "    def fit(self, dataUsers, dataItems):\n",
    "        self.p = {}\n",
    "        self.q = {}\n",
    "        self.loss = []\n",
    "        for i in xrange(1000):\n",
    "            loss = 0\n",
    "            for user in dataUsers.keys():\n",
    "                if not user in self.p:\n",
    "                    self.p[user] = np.random.rand(1,self.k)\n",
    "                for item in dataUsers[user].keys():\n",
    "                    if not item in self.q:\n",
    "                        self.q[item] = np.random.rand(self.k,1)\n",
    "                    tmp = dataUsers[user][item] - self.p[user].dot(self.q[item])[0][0]\n",
    "                    self.p[user] = (1 - self.lambd * self.eps) * self.p[user] + self.eps * 2 * tmp * self.q[item]\n",
    "                    self.q[item] = (1 - self.lambd * self.eps) * self.q[item] + self.eps * 2 * tmp * self.p[user]\n",
    "                    #self.p[user] = (1 - self.lambd * self.eps) * self.p[user] - self.eps * 2 * tmp * self.q[item]\n",
    "                    #self.q[item] = (1 - self.lambd * self.eps) * self.q[item] - self.eps * 2 * tmp * self.p[user]\n",
    "                    loss = loss + tmp*tmp #Sans régularisation\n",
    "            self.loss.append(loss)\n",
    "            if (i % 10 == 0):\n",
    "                print i, loss\n",
    "    def predict(self, couplesTest):\n",
    "        pred = np.zeros(len(couplesTest))\n",
    "        for ind,c in enumerate(couplesTest):\n",
    "            pred[ind] = self.p[c[0]].dot(self.q[c[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 234222.924798\n",
      "10 203548.029487\n",
      "20 179483.066694\n",
      "30 160742.073762\n",
      "40 146182.272231\n",
      "50 134845.056737\n",
      "60 125961.10847\n",
      "70 118932.949467\n",
      "80 113307.176138\n",
      "90 108744.836121\n",
      "100 104994.595042\n",
      "110 101870.552871\n",
      "120 99234.9227778\n",
      "130 96984.9995591\n",
      "140 95043.587144\n",
      "150 93352.068615\n",
      "160 91865.4272423\n",
      "170 90548.6774822\n",
      "180 89374.3021428\n",
      "190 88320.403088\n",
      "200 87369.3572141\n",
      "210 86506.8309932\n",
      "220 85721.0507314\n",
      "230 85002.2564653\n",
      "240 84342.2888575\n",
      "250 83734.2733285\n",
      "260 83172.3759976\n",
      "270 82651.6131999\n",
      "280 82167.7013922\n",
      "290 81716.9378135\n",
      "300 81296.1047931\n",
      "310 80902.3924133\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-9b2725db86c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatrixFactorisation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainUsers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainItems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestCouples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-cf30fbf9a3b5>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataUsers, dataItems)\u001b[0m\n\u001b[0;32m     20\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                     \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataUsers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlambd\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meps\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtmp\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlambd\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meps\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtmp\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                     \u001b[1;31m#self.p[user] = (1 - self.lambd * self.eps) * self.p[user] - self.eps * 2 * tmp * self.q[item]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model3 = matrixFactorisation(10)\n",
    "model3.fit(trainUsers, trainItems)\n",
    "pred = model3.predict(testCouples)\n",
    "print pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorisation de Matrices avec biais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class matrixFactorisation():\n",
    "    def __init__(self, k, lambd=0.1, eps=1e-5, maxIter=1000):\n",
    "        self.k = k\n",
    "        self.lambd = lambd\n",
    "        self.eps = eps\n",
    "        self.maxIter = maxIter\n",
    "    def fit(self, dataUsers, dataItems):\n",
    "        self.p = {}\n",
    "        self.q = {}\n",
    "        self.bu = {}\n",
    "        self.bi = {}\n",
    "        self.mu = np.random.random() * 2 - 1\n",
    "        self.loss = []\n",
    "        for i in xrange(1000):\n",
    "            loss = 0\n",
    "            for user in dataUsers.keys():\n",
    "                if not user in self.p:\n",
    "                    self.p[user] = np.random.rand(1,self.k) * 2 - 1\n",
    "                    self.bu[user] = np.random.rand() * 2 - 1\n",
    "                for item in dataUsers[user].keys():\n",
    "                    if not item in self.q:\n",
    "                        self.q[item] = np.random.rand(self.k,1) * 2 - 1\n",
    "                        self.bi[item] = np.random.rand() * 2 - 1\n",
    "                    tmp = dataUsers[user][item] - (self.mu + self.bi[item] + self.bu[user] + self.p[user].dot(self.q[item])[0][0])\n",
    "                    self.p[user] = (1 - self.lambd * self.eps) * self.p[user] + self.eps * 2 * tmp * self.q[item]\n",
    "                    self.q[item] = (1 - self.lambd * self.eps) * self.q[item] + self.eps * 2 * tmp * self.p[user]\n",
    "                    self.bu[user] = (1 - self.lambd * self.eps) * self.bu[user] + self.eps * 2 * tmp\n",
    "                    self.bi[item] = (1 - self.lambd * self.eps) * self.bi[item] + self.eps * 2 * tmp\n",
    "                    self.mu = (1 - self.lambd * self.eps) * self.mu + self.eps * 2 * tmp\n",
    "                    #self.p[user] = (1 - self.lambd * self.eps) * self.p[user] - self.eps * 2 * tmp * self.q[item]\n",
    "                    #self.q[item] = (1 - self.lambd * self.eps) * self.q[item] - self.eps * 2 * tmp * self.p[user]\n",
    "                    loss = loss + tmp*tmp #Sans régularisation\n",
    "            self.loss.append(loss)\n",
    "            if (i % 10 == 0):\n",
    "                print i, loss\n",
    "    def predict(self, couplesTest):\n",
    "        pred = np.zeros(len(couplesTest))\n",
    "        for ind,c in enumerate(couplesTest):\n",
    "            pred[ind] = self.mu + self.bi[c[0]] + self.bi[c[1]] + self.p[c[0]].dot(self.q[c[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 547034.284413\n",
      "10 244212.961125\n",
      "20 238170.674278\n",
      "30 232796.285584\n",
      "40 228012.594049\n",
      "50 223755.878866\n",
      "60 219973.524692\n",
      "70 216622.185908\n",
      "80 213666.369797\n",
      "90 211077.353156\n",
      "100 208832.370795\n",
      "110 206914.03281\n",
      "120 205309.942387\n",
      "130 204012.498662\n",
      "140 203018.881106\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-d4b24691d1a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatrixFactorisation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainUsers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainItems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestCouples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-c69376a9d6b9>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataUsers, dataItems)\u001b[0m\n\u001b[0;32m     22\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m                     \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataUsers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmu\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbu\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlambd\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meps\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtmp\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlambd\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meps\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtmp\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model4 = matrixFactorisation(10)\n",
    "model4.fit(trainUsers, trainItems)\n",
    "pred = model4.predict(testCouples)\n",
    "print pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 2\n",
    "u = 1\n",
    "if items[i] in data[users[u]]:\n",
    "    print data[users[u]][items[i]]\n",
    "else:\n",
    "    print 0\n",
    "print couples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.72955982213\n",
      "0.505221885261\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print np.random.rand(1,10).dot(np.random.rand(10,1))[0][0]\n",
    "print np.random.random() * 2 - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
